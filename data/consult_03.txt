Ollama — это инструмент для локального запуска больших языковых моделей. Он позволяет скачивать и запускать модели на собственном компьютере без отправки данных во внешние сервисы. Ollama предоставляет REST API на порту 11434 для взаимодействия с моделями.

Для генерации эмбеддингов в Ollama используется эндпоинт /api/embeddings. Ему передаётся JSON с названием модели и текстом, а в ответ приходит числовой вектор. Модель nomic-embed-text генерирует векторы размерностью 768, что достаточно для большинства задач семантического поиска.

Эмбеддинги позволяют измерять семантическую близость текстов. Два текста с похожим смыслом будут иметь близкие векторы, даже если они используют разные слова. Для сравнения векторов обычно применяется косинусное сходство — значение от -1 до 1, где 1 означает полное совпадение направлений векторов. Это основа для семантического поиска в RAG-системах.